{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import sys\n",
    "\n",
    "\n",
    "#hyper_parameter\n",
    "bigram_thresh = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing stemmer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "en_stop = set(stopwords.words('english'))\n",
    "p_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStemmedDocument(input_raw_data):\n",
    "\tdocs = input_raw_data\n",
    "\tnew_doc = []\n",
    "\tfor doc in docs:\n",
    "\t\traw = doc.lower()\n",
    "\t\traw = raw.replace(\"<br /><br />\", \" \")\n",
    "\t\ttokens = tokenizer.tokenize(raw)\n",
    "\t\tstopped_tokens = [token for token in tokens if token not in en_stop]\n",
    "\t\tstemmed_tokens = [p_stemmer.stem(token) for token in stopped_tokens]\n",
    "\t\tdocumentWords = ' '.join(stemmed_tokens)\n",
    "\t\tnew_doc.append(documentWords)\n",
    "\treturn new_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_name):\n",
    "\tfile = open(\"data/\" + file_name,\"r\")\n",
    "\tall_text = file.readlines()\n",
    "\tif len(all_text)==0:\n",
    "\t\tprint \"empty document\"\n",
    "\treturn all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dict(training_data,bigram):\n",
    "\tcount = 0\n",
    "\tvocab_dict = {}\n",
    "\tbigram_dict = {}\t\n",
    "\tfor document in training_data:\n",
    "\t\twords = document.split()\n",
    "\t\ti = 0\n",
    "\t\tfor word in words:\n",
    "\t\t\tif i > 0 and bigram:\n",
    "\t\t\t\tbigram_word = words[i-1] + \" \" + word\n",
    "\t\t\t\tif not bigram_word in bigram_dict.keys():\n",
    "\t\t\t\t\tbigram_dict[bigram_word] = 1\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tbigram_dict[bigram_word] +=1\n",
    "\t\t\tif not word in vocab_dict.keys():\n",
    "\t\t\t\tvocab_dict[word] = count\n",
    "\t\t\t\tcount += 1\n",
    "\t\t\ti +=1\n",
    "\tif bigram:\n",
    "\t\tfor key in bigram_dict.keys():\n",
    "\t\t\tif bigram_dict[key] >= bigram_thresh:\n",
    "\t\t\t\tvocab_dict[key] = count\n",
    "\t\t\t\tcount += 1\n",
    "\treturn vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(test_documents,labels,bigram):\n",
    "\tcorrect = 0.0\n",
    "\tfor i in range(len(test_documents)):\n",
    "\t\tpredicted_class = predict(test_documents[i],bigram)\n",
    "\t\tif labels[i].split()[0] in label_dict.keys():\n",
    "\t\t\texpected_class = label_dict[labels[i].split()[0]]\n",
    "\t\t\tif predicted_class==expected_class:\n",
    "\t\t\t\tcorrect+=1\n",
    "\treturn correct/len(test_documents)\n",
    "\n",
    "def majority_accuracy(test_documents,labels):\n",
    "\tcorrect = 0.0\n",
    "\tfor i in range(len(test_documents)):\n",
    "\t\tpredicted_class = np.argmax(label_freq)\n",
    "\t\tif labels[i].split()[0] in label_dict.keys():\n",
    "\t\t\texpected_class = label_dict[labels[i].split()[0]]\n",
    "\t\t\tif predicted_class==expected_class:\n",
    "\t\t\t\tcorrect+=1\n",
    "\treturn correct/len(test_documents)\n",
    "\n",
    "def random_accuracy(test_documents,labels):\n",
    "\tcorrect = 0.0\n",
    "\tfor i in range(len(test_documents)):\n",
    "\t\tpredicted_class = random.randint(0,len(label_dict))\n",
    "\t\tif labels[i].split()[0] in label_dict.keys():\n",
    "\t\t\texpected_class = label_dict[labels[i].split()[0]]\n",
    "\t\t\tif predicted_class==expected_class:\n",
    "\t\t\t\tcorrect+=1\n",
    "\treturn correct/len(test_documents)\n",
    "\n",
    "def confusion_matrix(test_documents,labels,bigram):\n",
    "\tcorrect = np.zeros((len(label_dict),len(label_dict)))\n",
    "\tfor i in range(len(test_documents)):\n",
    "\t\tpredicted_class = predict(test_documents[i],bigram)\n",
    "\t\tif labels[i].split()[0] in label_dict.keys():\n",
    "\t\t\texpected_class = label_dict[labels[i].split()[0]]\n",
    "\t\t\tcorrect[expected_class][predicted_class] += 1\n",
    "\treturn correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = read_data(\"imdb_train_text.txt\")\n",
    "# training_data = getStemmedDocument(training_data)\n",
    "training_labels = read_data(\"imdb_train_labels.txt\")\n",
    "test_data = read_data(\"imdb_test_text.txt\")\n",
    "# test_data = getStemmedDocument(test_data)\n",
    "test_labels = read_data(\"imdb_test_labels.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = make_dict(training_labels,0)\t\n",
    "number_classes = len(label_dict)\n",
    "# vocab_dict = make_dict(training_data,0)\n",
    "vocab_dict = make_dict(training_data,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_matrix,label_freq = make_matrix(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_accuracy = accuracy(training_data,training_labels,1)\n",
    "test_accuracy = confusion_matrix(test_data,test_labels,1)\n",
    "# print test_accuracy\n",
    "print test_accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
